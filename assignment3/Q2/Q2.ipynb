{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0996488-76f1-485b-81dd-6497bce97dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "fc2c02df-79a6-4af0-9bcd-a74479bfd5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))\n",
    "\n",
    "def sigmoid_dv(x):\n",
    "    return sigmoid(x)*(1-sigmoid(x))\n",
    "\n",
    "def MSE_loss(Y_true, Y_pred):\n",
    "    return ((Y_pred-Y_true)**2).sum(axis=1).mean()/2\n",
    "\n",
    "def MSE_loss_dv(Y_true, Y_pred):\n",
    "    return (Y_pred-Y_true).mean(axis=0)\n",
    "\n",
    "def constant_lr(epoch, batch):\n",
    "    return 0.1\n",
    "\n",
    "def epoch_lr(epoch, batch):\n",
    "    return 0.1/np.sqrt(epoch)\n",
    "\n",
    "class NeuralNetwork:\n",
    "    \n",
    "    def __init__(self, M, n, layers, r, activation=sigmoid, activation_dv=sigmoid_dv, loss=MSE_loss, loss_dv=MSE_loss_dv, lr_fn=constant_lr):\n",
    "        l = [n] + layers + [r]\n",
    "        self.weights = [np.random.randn(l[i], l[i+1])*0.05 for i in range(len(l)-1)]\n",
    "        self.biases = [np.random.randn(l[i+1])*0.05 for i in range(len(l)-1)]\n",
    "        self.Z = []\n",
    "        self.L = []\n",
    "        self.activation = activation\n",
    "        self.activation_dv = activation_dv\n",
    "        self.loss = loss\n",
    "        self.loss_dv = loss_dv\n",
    "        self.n = len(self.weights)\n",
    "        self.lr_fn = lr_fn\n",
    "        self.M = M\n",
    "    \n",
    "    def backward(self, y):\n",
    "        # returns weight matrix derivatives with the shapes (n,l_1), (l_1,l_2), \\ldots, (l_L,r) and\n",
    "        # bias derivatives with the shapes l_1, l_2, \\ldots, l_L, r\n",
    "        \n",
    "        wt_dv = []\n",
    "        bias_dv = []\n",
    "        \n",
    "        # first get del L\n",
    "        dL = self.loss_dv(y,self.L[-1]) # change to using sigmoid derivative here, as output layer will always be sigmoid\n",
    "        #print(dL.shape)\n",
    "        for i in range(self.n-1,-1,-1):\n",
    "            z_dv = dL*(self.activation_dv(self.Z[i]).mean(axis=0))\n",
    "            # print(self.L[i].shape)\n",
    "            # print(self.L[i].mean(axis=0).reshape(-1,1).shape)\n",
    "            # print(z_dv.shape)\n",
    "            wt_dv.append(np.outer(self.L[i].mean(axis=0),z_dv))\n",
    "            bias_dv.append(z_dv)\n",
    "            dL = z_dv@self.weights[i].T\n",
    "        \n",
    "        return wt_dv[::-1], bias_dv[::-1]\n",
    "\n",
    "    def forward(self, X):\n",
    "        # populates self.Z and self.L with outputs of each layer, and finally returns the output of the \n",
    "        # final layer\n",
    "        \n",
    "        self.L = []\n",
    "        self.Z = []\n",
    "        self.L.append(X)\n",
    "        for i in range(self.n):\n",
    "            self.Z.append(self.L[-1]@self.weights[i] + self.biases[i])\n",
    "            self.L.append(self.activation(self.Z[-1]))\n",
    "            \n",
    "        return self.L[-1]\n",
    "\n",
    "    def backpropagate(self, wt_dv, bias_dv, eta=0.1):\n",
    "        for (i,(dw,db)) in enumerate(zip(wt_dv,bias_dv)):\n",
    "            self.weights[i] -= eta*dw\n",
    "            self.biases[i] -= eta*db\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \n",
    "        # training\n",
    "        n_batches = X.shape[0]//self.M\n",
    "        y_dec = np.argmax(y,axis=1).flatten()\n",
    "        # train for 300 epochs\n",
    "        for epoch in range(300):\n",
    "            for batch in range(n_batches):\n",
    "                preds = self.forward(X[batch*self.M:(batch+1)*self.M])\n",
    "                wt_dv, bias_dv = self.backward(y[batch*self.M:(batch+1)*self.M])\n",
    "                self.backpropagate(wt_dv, bias_dv, eta=self.lr_fn(epoch, batch))\n",
    "            if (epoch%10 == 9):\n",
    "                print(f\"Epoch {epoch+1}\")\n",
    "                print(f\"  Training set accuracy: {accuracy_score(y_dec,self.predict(X))}\")\n",
    "                print(f\"  Loss: {self.loss(y,self.L[-1])}\")\n",
    "                print(\"\")\n",
    "            \n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.forward(X),axis=1).flatten()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82a5fa6e-be39-4ad1-b42c-19382dec6594",
   "metadata": {},
   "source": [
    "# Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c16ae036-72be-439c-baf4-03e1ea851384",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(path):\n",
    "    mat = np.loadtxt(path, delimiter=\",\")\n",
    "    X,y = mat[:,:28*28],mat[:,28*28].flatten().astype(np.int32)\n",
    "    y_enc = np.eye(10)[y]\n",
    "    return X,y,y_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "12008ad8-bea7-4527-8b68-3571346e20b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "dpath = '../data/part2_data'\n",
    "X_train, y_train, y_train_onehot = load_dataset(f\"{dpath}/fmnist_train.csv\")\n",
    "X_test, y_test, y_test_onehot = load_dataset(f\"{dpath}/fmnist_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "339455f5-0e73-4a36-a799-9a8be5e27b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetwork(100, 784, [100], 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "921bf51b-1945-475d-8fd0-c50516a8e596",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n",
      "  Training set accuracy: 0.4074\n",
      "  Loss: 0.43218071400111024\n",
      "\n",
      "Epoch 20\n",
      "  Training set accuracy: 0.5288833333333334\n",
      "  Loss: 0.4116071181448074\n",
      "\n",
      "Epoch 30\n",
      "  Training set accuracy: 0.5470666666666667\n",
      "  Loss: 0.3937834693042511\n",
      "\n",
      "Epoch 40\n",
      "  Training set accuracy: 0.5650833333333334\n",
      "  Loss: 0.3776370134078666\n",
      "\n",
      "Epoch 50\n",
      "  Training set accuracy: 0.5835833333333333\n",
      "  Loss: 0.3635554943197915\n",
      "\n",
      "Epoch 60\n",
      "  Training set accuracy: 0.59855\n",
      "  Loss: 0.35042287286179036\n",
      "\n",
      "Epoch 70\n",
      "  Training set accuracy: 0.6063833333333334\n",
      "  Loss: 0.3402978933648469\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-112-cede6a7d0f14>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#import warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m#warnings.filterwarnings('ignore')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_onehot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-110-f48e63c4ac7f>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m300\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_batches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m                 \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m                 \u001b[0mwt_dv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_dv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mwt_dv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias_dv\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meta\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-110-f48e63c4ac7f>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     62\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbiases\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZ\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#import warnings\n",
    "#warnings.filterwarnings('ignore')\n",
    "net.fit(X_train, y_train_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "98d684b2-9c52-4928-865f-7bb781520528",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6902\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "preds = net.predict(X_test)\n",
    "score = accuracy_score(y_test, preds)\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7381e331-a93c-412f-b7a9-8978b28f8b96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 ... 6 0 2]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3bb114db-a141-47c4-b3f1-3ef2b94d653f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       ...,\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.],\n",
       "       [1., 1., 1., ..., 1., 1., 1.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.forward(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "d51f1495-7be4-452c-b5f0-1b9315f48128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 1.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "896bfc19-8fe9-4b21-8ff6-676a00ec8f43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.01531875, 0.2341253 , 0.88297172, ..., 0.91529547, 0.0530619 ,\n",
       "        0.99801892],\n",
       "       [0.77981012, 0.05530899, 0.92192286, ..., 0.28482677, 0.65887782,\n",
       "        0.57785324],\n",
       "       [0.72118082, 0.23557015, 0.63697934, ..., 0.14700197, 0.19349988,\n",
       "        0.01488687],\n",
       "       ...,\n",
       "       [0.88380899, 0.61386444, 0.43785856, ..., 0.8318427 , 0.05593743,\n",
       "        0.35893407],\n",
       "       [0.42203514, 0.37888886, 0.25573292, ..., 0.17721268, 0.66253352,\n",
       "        0.05657037],\n",
       "       [0.41270869, 0.80240223, 0.87296582, ..., 0.76340554, 0.542691  ,\n",
       "        0.85509081]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.weights[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1db926-74d5-456f-bef2-20c5863493f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
